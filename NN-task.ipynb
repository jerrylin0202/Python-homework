{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 老師的神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.0904 - acc: 0.0991 - val_loss: 0.0901 - val_acc: 0.1009\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0900 - acc: 0.0992 - val_loss: 0.0898 - val_acc: 0.1009\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0897 - acc: 0.0991 - val_loss: 0.0896 - val_acc: 0.1009\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0896 - acc: 0.0992 - val_loss: 0.0895 - val_acc: 0.1009\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0894 - acc: 0.0992 - val_loss: 0.0893 - val_acc: 0.1009\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0893 - acc: 0.0991 - val_loss: 0.0892 - val_acc: 0.1009\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0892 - acc: 0.0992 - val_loss: 0.0891 - val_acc: 0.1009\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0891 - acc: 0.0991 - val_loss: 0.0890 - val_acc: 0.1009\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0890 - acc: 0.1683 - val_loss: 0.0890 - val_acc: 0.1987\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0889 - acc: 0.197 - 2s 30us/step - loss: 0.0889 - acc: 0.1976 - val_loss: 0.0889 - val_acc: 0.2026\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0888 - acc: 0.1995 - val_loss: 0.0888 - val_acc: 0.2037\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0888 - acc: 0.2009 - val_loss: 0.0887 - val_acc: 0.2049\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0887 - acc: 0.2024 - val_loss: 0.0886 - val_acc: 0.2055\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0886 - acc: 0.2028 - val_loss: 0.0885 - val_acc: 0.2062\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.0885 - acc: 0.2031 - val_loss: 0.0884 - val_acc: 0.2065\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.0884 - acc: 0.2037 - val_loss: 0.0883 - val_acc: 0.2066\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0882 - acc: 0.2039 - val_loss: 0.0881 - val_acc: 0.2071\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0881 - acc: 0.2045 - val_loss: 0.0880 - val_acc: 0.2074\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0879 - acc: 0.2051 - val_loss: 0.0878 - val_acc: 0.2070\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0878 - acc: 0.2044 - val_loss: 0.0876 - val_acc: 0.2078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1623ebf0cc0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='mse',optimizer=SGD(lr=0.087) ,metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=100, epochs=20,verbose=1, \n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 先試試改神經元個數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0881 - acc: 0.2566 - val_loss: 0.0848 - val_acc: 0.3353\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0819 - acc: 0.3692 - val_loss: 0.0785 - val_acc: 0.4335\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0754 - acc: 0.4953 - val_loss: 0.0721 - val_acc: 0.5512\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0693 - acc: 0.5696 - val_loss: 0.0661 - val_acc: 0.6007\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.0633 - acc: 0.6141 - val_loss: 0.0601 - val_acc: 0.6344\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0573 - acc: 0.6531 - val_loss: 0.0542 - val_acc: 0.6891\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0517 - acc: 0.7076 - val_loss: 0.0487 - val_acc: 0.7454\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0465 - acc: 0.7586 - val_loss: 0.0438 - val_acc: 0.7792\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0417 - acc: 0.7865 - val_loss: 0.0392 - val_acc: 0.8036\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.0376 - acc: 0.8040 - val_loss: 0.0353 - val_acc: 0.8149\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.0340 - acc: 0.8137 - val_loss: 0.0319 - val_acc: 0.8251\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.0309 - acc: 0.8277 - val_loss: 0.0290 - val_acc: 0.8484\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.0281 - acc: 0.8543 - val_loss: 0.0265 - val_acc: 0.8697\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.0257 - acc: 0.8753 - val_loss: 0.0242 - val_acc: 0.8851\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.0236 - acc: 0.8868 - val_loss: 0.0224 - val_acc: 0.8934\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0218 - acc: 0.8939 - val_loss: 0.0208 - val_acc: 0.8958\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.0203 - acc: 0.8985 - val_loss: 0.0194 - val_acc: 0.9036\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.0191 - acc: 0.9030 - val_loss: 0.0184 - val_acc: 0.9048\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.0181 - acc: 0.9067 - val_loss: 0.0175 - val_acc: 0.9086\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.0172 - acc: 0.9098 - val_loss: 0.0167 - val_acc: 0.9094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x162410bfac8>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='mse',optimizer=SGD(lr=0.087) ,metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=100, epochs=20,verbose=1, \n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 把隱藏層神經元個數變多，20次以內準確率能達到90%\n",
    "\n",
    "發現若是隱藏層神經元個數從少到多輸出的預測結果較差。而從多到少的預測效果較好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 換一下激發函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0902 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1136\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1136\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1136\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1136\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1136\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1136\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1136\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1136\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1136\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1136\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1136\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1136\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1136\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1136\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1136\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1136\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1136\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1136\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1136\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16241368278>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=784))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='mse',optimizer=SGD(lr=0.087) ,metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=100, epochs=20,verbose=1, \n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.0893 - acc: 0.2014 - val_loss: 0.0831 - val_acc: 0.2696\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0806 - acc: 0.2776 - val_loss: 0.0769 - val_acc: 0.2897\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0760 - acc: 0.2828 - val_loss: 0.0737 - val_acc: 0.2936\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0744 - acc: 0.2870 - val_loss: 0.0728 - val_acc: 0.2946\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0737 - acc: 0.2891 - val_loss: 0.0728 - val_acc: 0.2881\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0732 - acc: 0.2905 - val_loss: 0.0720 - val_acc: 0.2952\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0731 - acc: 0.2920 - val_loss: 0.0720 - val_acc: 0.2937\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0729 - acc: 0.2906 - val_loss: 0.0717 - val_acc: 0.2992\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0726 - acc: 0.2935 - val_loss: 0.0715 - val_acc: 0.2988\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0726 - acc: 0.2935 - val_loss: 0.0717 - val_acc: 0.2950\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0724 - acc: 0.2944 - val_loss: 0.0715 - val_acc: 0.2987\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0724 - acc: 0.2950 - val_loss: 0.0715 - val_acc: 0.2994\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0723 - acc: 0.2947 - val_loss: 0.0713 - val_acc: 0.2984\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0722 - acc: 0.2953 - val_loss: 0.0716 - val_acc: 0.3011\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0723 - acc: 0.2961 - val_loss: 0.0730 - val_acc: 0.2907\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0722 - acc: 0.2949 - val_loss: 0.0713 - val_acc: 0.3002\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0722 - acc: 0.2953 - val_loss: 0.0714 - val_acc: 0.2986\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0720 - acc: 0.2958 - val_loss: 0.0714 - val_acc: 0.2967\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0721 - acc: 0.2950 - val_loss: 0.0715 - val_acc: 0.2969\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.0721 - acc: 0.2961 - val_loss: 0.0712 - val_acc: 0.2984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16241607da0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=784))\n",
    "model.add(Activation('selu'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('selu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='mse',optimizer=SGD(lr=0.087) ,metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=100, epochs=20,verbose=1, \n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0841 - acc: 0.1844 - val_loss: 0.0811 - val_acc: 0.2055\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0811 - acc: 0.2072 - val_loss: 0.0802 - val_acc: 0.2116\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0806 - acc: 0.2081 - val_loss: 0.0798 - val_acc: 0.2116\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0802 - acc: 0.2247 - val_loss: 0.0791 - val_acc: 0.2482\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0793 - acc: 0.2460 - val_loss: 0.0785 - val_acc: 0.2552\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0781 - acc: 0.2591 - val_loss: 0.0764 - val_acc: 0.2789\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0767 - acc: 0.2780 - val_loss: 0.0755 - val_acc: 0.2876\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0757 - acc: 0.2845 - val_loss: 0.0744 - val_acc: 0.2875\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0750 - acc: 0.2845 - val_loss: 0.0736 - val_acc: 0.2955\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0745 - acc: 0.2850 - val_loss: 0.0732 - val_acc: 0.2953\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0743 - acc: 0.2856 - val_loss: 0.0734 - val_acc: 0.2881\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0742 - acc: 0.2882 - val_loss: 0.0732 - val_acc: 0.2948\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0740 - acc: 0.2901 - val_loss: 0.0735 - val_acc: 0.2956\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0739 - acc: 0.2865 - val_loss: 0.0728 - val_acc: 0.2936\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0737 - acc: 0.2892 - val_loss: 0.0732 - val_acc: 0.2905\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0737 - acc: 0.2924 - val_loss: 0.0730 - val_acc: 0.2951\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0735 - acc: 0.2882 - val_loss: 0.0727 - val_acc: 0.2947\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0735 - acc: 0.2895 - val_loss: 0.0728 - val_acc: 0.2952\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0735 - acc: 0.2916 - val_loss: 0.0733 - val_acc: 0.2978\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0735 - acc: 0.2910 - val_loss: 0.0731 - val_acc: 0.2900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x162419054e0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=784))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='mse',optimizer=SGD(lr=0.087) ,metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=100, epochs=20,verbose=1, \n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0878 - acc: 0.1642 - val_loss: 0.0854 - val_acc: 0.2358\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0845 - acc: 0.2579 - val_loss: 0.0836 - val_acc: 0.3013\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0826 - acc: 0.3254 - val_loss: 0.0818 - val_acc: 0.3491\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0812 - acc: 0.3550 - val_loss: 0.0802 - val_acc: 0.3819\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0799 - acc: 0.3641 - val_loss: 0.0793 - val_acc: 0.3604\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0786 - acc: 0.3582 - val_loss: 0.0780 - val_acc: 0.3365\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0773 - acc: 0.3452 - val_loss: 0.0768 - val_acc: 0.3446\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0763 - acc: 0.3490 - val_loss: 0.0756 - val_acc: 0.3521\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0755 - acc: 0.3478 - val_loss: 0.0748 - val_acc: 0.3499\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0744 - acc: 0.3506 - val_loss: 0.0738 - val_acc: 0.3495\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0735 - acc: 0.3515 - val_loss: 0.0731 - val_acc: 0.3493\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0725 - acc: 0.3517 - val_loss: 0.0727 - val_acc: 0.3404\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0723 - acc: 0.3496 - val_loss: 0.0730 - val_acc: 0.3542\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0715 - acc: 0.3518 - val_loss: 0.0704 - val_acc: 0.3545\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0710 - acc: 0.3535 - val_loss: 0.0701 - val_acc: 0.3509\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0709 - acc: 0.3461 - val_loss: 0.0709 - val_acc: 0.3295\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0699 - acc: 0.3548 - val_loss: 0.0699 - val_acc: 0.3534\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0689 - acc: 0.3709 - val_loss: 0.0678 - val_acc: 0.4424\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0684 - acc: 0.4366 - val_loss: 0.0676 - val_acc: 0.4325\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0678 - acc: 0.4371 - val_loss: 0.0683 - val_acc: 0.4306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16242ba59e8>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=784))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='mse',optimizer=SGD(lr=0.087) ,metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=100, epochs=20,verbose=1, \n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 試試看改learning rate\n",
    "用sigmoid當激發函數，lr=1時，最後可以學到50%左右的正確率，但還是沒有達標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0880 - acc: 0.1030 - val_loss: 0.0863 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0850 - acc: 0.1865 - val_loss: 0.0841 - val_acc: 0.2090\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0822 - acc: 0.2097 - val_loss: 0.0807 - val_acc: 0.2115\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0801 - acc: 0.2168 - val_loss: 0.0789 - val_acc: 0.2253\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0787 - acc: 0.2761 - val_loss: 0.0782 - val_acc: 0.2850\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0777 - acc: 0.3019 - val_loss: 0.0770 - val_acc: 0.2982\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0765 - acc: 0.3001 - val_loss: 0.0756 - val_acc: 0.3009\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0757 - acc: 0.2994 - val_loss: 0.0748 - val_acc: 0.3026\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0749 - acc: 0.3000 - val_loss: 0.0748 - val_acc: 0.2944\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0744 - acc: 0.2993 - val_loss: 0.0742 - val_acc: 0.2976\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0741 - acc: 0.2985 - val_loss: 0.0772 - val_acc: 0.2727\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0749 - acc: 0.3269 - val_loss: 0.0735 - val_acc: 0.2978\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0737 - acc: 0.3131 - val_loss: 0.0729 - val_acc: 0.3014\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0733 - acc: 0.3144 - val_loss: 0.0729 - val_acc: 0.3860\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0731 - acc: 0.3740 - val_loss: 0.0725 - val_acc: 0.3814\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0730 - acc: 0.3834 - val_loss: 0.0741 - val_acc: 0.3628\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0728 - acc: 0.3790 - val_loss: 0.0723 - val_acc: 0.3860\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0726 - acc: 0.3819 - val_loss: 0.0724 - val_acc: 0.3800\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0724 - acc: 0.3796 - val_loss: 0.0721 - val_acc: 0.3728\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0724 - acc: 0.3790 - val_loss: 0.0719 - val_acc: 0.3881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16242e507b8>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='mse',optimizer=SGD(lr=1) ,metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=100, epochs=20,verbose=1, \n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 2.2794 - acc: 0.1229 - val_loss: 2.3105 - val_acc: 0.0979\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.3071 - acc: 0.1043 - val_loss: 2.3052 - val_acc: 0.0897\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.3067 - acc: 0.1041 - val_loss: 2.3150 - val_acc: 0.1033\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 2.3083 - acc: 0.1045 - val_loss: 2.3095 - val_acc: 0.0985\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.3078 - acc: 0.1032 - val_loss: 2.3051 - val_acc: 0.1140\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.3072 - acc: 0.1069 - val_loss: 2.3053 - val_acc: 0.1140\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.3071 - acc: 0.1069 - val_loss: 2.3099 - val_acc: 0.0982\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 2.3081 - acc: 0.1024 - val_loss: 2.3068 - val_acc: 0.1137\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.3069 - acc: 0.1057 - val_loss: 2.3150 - val_acc: 0.0979\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.3081 - acc: 0.1039 - val_loss: 2.3035 - val_acc: 0.1140\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.3066 - acc: 0.1063 - val_loss: 2.3105 - val_acc: 0.1033\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.3086 - acc: 0.1034 - val_loss: 2.3040 - val_acc: 0.0982\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.3073 - acc: 0.1049 - val_loss: 2.3016 - val_acc: 0.1014\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 2.3069 - acc: 0.1065 - val_loss: 2.3037 - val_acc: 0.1037\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 2.3082 - acc: 0.1063 - val_loss: 2.3035 - val_acc: 0.1030\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 2.3066 - acc: 0.1044 - val_loss: 2.3048 - val_acc: 0.1140\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 2.3069 - acc: 0.1071 - val_loss: 2.3067 - val_acc: 0.1011\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 2.3072 - acc: 0.1036 - val_loss: 2.3064 - val_acc: 0.1030\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.3075 - acc: 0.1051 - val_loss: 2.3079 - val_acc: 0.1140\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.3077 - acc: 0.1041 - val_loss: 2.3069 - val_acc: 0.0982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1623d37ae48>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.1) ,metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=100, epochs=20,verbose=1, \n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 只改動參數但發現預測的結果一直都蠻差的，因此推測應該是神經元個數太少了\n",
    "--------\n",
    "### 調整各種參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0328 - acc: 0.8032 - val_loss: 0.0154 - val_acc: 0.9107\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.0135 - acc: 0.9172 - val_loss: 0.0120 - val_acc: 0.9250\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0109 - acc: 0.9323 - val_loss: 0.0105 - val_acc: 0.9346\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.0096 - acc: 0.9392 - val_loss: 0.0089 - val_acc: 0.9443\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0086 - acc: 0.9452 - val_loss: 0.0081 - val_acc: 0.9482\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0081 - acc: 0.9475 - val_loss: 0.0076 - val_acc: 0.9490\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0077 - acc: 0.9513 - val_loss: 0.0075 - val_acc: 0.9508\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.0070 - acc: 0.9554 - val_loss: 0.0074 - val_acc: 0.9520\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0067 - acc: 0.9571 - val_loss: 0.0069 - val_acc: 0.9565\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0066 - acc: 0.9588 - val_loss: 0.0070 - val_acc: 0.9545\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0065 - acc: 0.9579 - val_loss: 0.0067 - val_acc: 0.9565\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0062 - acc: 0.9605 - val_loss: 0.0063 - val_acc: 0.9587\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0059 - acc: 0.9626 - val_loss: 0.0063 - val_acc: 0.9601\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.0060 - acc: 0.9614 - val_loss: 0.0070 - val_acc: 0.9550\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.0061 - acc: 0.9610 - val_loss: 0.0065 - val_acc: 0.9573\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0058 - acc: 0.9633 - val_loss: 0.0060 - val_acc: 0.9627\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.0059 - acc: 0.9625 - val_loss: 0.0065 - val_acc: 0.9575\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0060 - acc: 0.9620 - val_loss: 0.0064 - val_acc: 0.9586\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.0057 - acc: 0.9633 - val_loss: 0.0063 - val_acc: 0.9583\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.0055 - acc: 0.9648 - val_loss: 0.0060 - val_acc: 0.9605\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0055 - acc: 0.9648 - val_loss: 0.0066 - val_acc: 0.9573\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.0058 - acc: 0.9631 - val_loss: 0.0061 - val_acc: 0.9601\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0055 - acc: 0.9643 - val_loss: 0.0062 - val_acc: 0.9601\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.0057 - acc: 0.9636 - val_loss: 0.0058 - val_acc: 0.9617\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0052 - acc: 0.9669 - val_loss: 0.0074 - val_acc: 0.9512\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0055 - acc: 0.9649 - val_loss: 0.0055 - val_acc: 0.9649\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.0051 - acc: 0.9671 - val_loss: 0.0053 - val_acc: 0.9665\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0048 - acc: 0.9690 - val_loss: 0.0059 - val_acc: 0.9623\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0050 - acc: 0.9683 - val_loss: 0.0056 - val_acc: 0.9637\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0050 - acc: 0.9681 - val_loss: 0.0057 - val_acc: 0.9625\n"
     ]
    }
   ],
   "source": [
    "model_mix1 = Sequential()\n",
    "model_mix1.add(Dense(200, input_dim=784))\n",
    "model_mix1.add(Activation('relu'))\n",
    "model_mix1.add(Dense(50))\n",
    "model_mix1.add(Activation('sigmoid'))\n",
    "model_mix1.add(Dense(10))\n",
    "model_mix1.add(Activation('softmax'))\n",
    "model_mix1.compile(loss='mse',optimizer=Adam(lr=0.001) ,metrics=['accuracy'])\n",
    "model_mix1_fit=model_mix1.fit(x_train, y_train, batch_size=200, epochs=30,verbose=1, \n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 101us/step\n",
      "testing data 的正確率： 0.9609\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict_classes(x_test)\n",
    "score = model_mix1.evaluate(x_test, y_test)\n",
    "print('testing data 的正確率：', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0323 - acc: 0.8085 - val_loss: 0.0100 - val_acc: 0.9382\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.0086 - acc: 0.9463 - val_loss: 0.0077 - val_acc: 0.9501\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0066 - acc: 0.9587 - val_loss: 0.0065 - val_acc: 0.9573\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0057 - acc: 0.9640 - val_loss: 0.0062 - val_acc: 0.9599\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0050 - acc: 0.9685 - val_loss: 0.0053 - val_acc: 0.9670\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.0044 - acc: 0.9719 - val_loss: 0.0049 - val_acc: 0.9681\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0042 - acc: 0.9728 - val_loss: 0.0053 - val_acc: 0.9677\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.0040 - acc: 0.9754 - val_loss: 0.0051 - val_acc: 0.9675\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.0039 - acc: 0.9751 - val_loss: 0.0047 - val_acc: 0.9701\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0035 - acc: 0.9782 - val_loss: 0.0046 - val_acc: 0.9705\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0034 - acc: 0.9784 - val_loss: 0.0046 - val_acc: 0.9702\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0030 - acc: 0.9811 - val_loss: 0.0044 - val_acc: 0.9719\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0028 - acc: 0.9827 - val_loss: 0.0046 - val_acc: 0.9701\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0028 - acc: 0.9829 - val_loss: 0.0040 - val_acc: 0.9743\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0029 - acc: 0.9816 - val_loss: 0.0046 - val_acc: 0.9700\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0028 - acc: 0.9821 - val_loss: 0.0042 - val_acc: 0.9729\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0028 - acc: 0.9825 - val_loss: 0.0043 - val_acc: 0.9722\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0027 - acc: 0.9836 - val_loss: 0.0041 - val_acc: 0.9750\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0027 - acc: 0.9830 - val_loss: 0.0040 - val_acc: 0.9755\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0023 - acc: 0.9857 - val_loss: 0.0042 - val_acc: 0.9727\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0025 - acc: 0.9842 - val_loss: 0.0052 - val_acc: 0.9669\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0024 - acc: 0.9849 - val_loss: 0.0044 - val_acc: 0.9726\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.0024 - acc: 0.9850 - val_loss: 0.0039 - val_acc: 0.9748\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0024 - acc: 0.9851 - val_loss: 0.0041 - val_acc: 0.9741\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.0023 - acc: 0.9856 - val_loss: 0.0039 - val_acc: 0.9754\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0025 - acc: 0.9846 - val_loss: 0.0037 - val_acc: 0.9770\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0024 - acc: 0.9853 - val_loss: 0.0043 - val_acc: 0.9713\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0023 - acc: 0.9854 - val_loss: 0.0041 - val_acc: 0.9745\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0023 - acc: 0.9855 - val_loss: 0.0040 - val_acc: 0.9740\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.0022 - acc: 0.9861 - val_loss: 0.0039 - val_acc: 0.9755\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0022 - acc: 0.9860 - val_loss: 0.0041 - val_acc: 0.9747\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0020 - acc: 0.9872 - val_loss: 0.0041 - val_acc: 0.9745\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0022 - acc: 0.9866 - val_loss: 0.0042 - val_acc: 0.9742\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.0021 - acc: 0.9867 - val_loss: 0.0048 - val_acc: 0.9689\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.0021 - acc: 0.9870 - val_loss: 0.0042 - val_acc: 0.9745\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.0022 - acc: 0.9862 - val_loss: 0.0041 - val_acc: 0.9742\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0022 - acc: 0.9865 - val_loss: 0.0039 - val_acc: 0.9756\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0019 - acc: 0.9880 - val_loss: 0.0042 - val_acc: 0.9740\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0020 - acc: 0.9878 - val_loss: 0.0047 - val_acc: 0.9706\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.0021 - acc: 0.9869 - val_loss: 0.0043 - val_acc: 0.9732\n"
     ]
    }
   ],
   "source": [
    "model_mix = Sequential()\n",
    "\n",
    "model_mix.add(Dense(200, input_dim=784))\n",
    "model_mix.add(Activation('relu'))\n",
    "model_mix.add(Dense(100))\n",
    "model_mix.add(Activation('relu'))\n",
    "model_mix.add(Dense(100))\n",
    "model_mix.add(Activation('sigmoid'))\n",
    "model_mix.add(Dense(100))\n",
    "model_mix.add(Activation('sigmoid'))\n",
    "model_mix.add(Dense(10))\n",
    "model_mix.add(Activation('softmax'))\n",
    "\n",
    "model_mix.compile(loss='mse',optimizer=Adam(lr=0.001) ,metrics=['accuracy'])\n",
    "\n",
    "model_mix_fit = model_mix.fit(x_train, y_train, batch_size=300, epochs=40,verbose=1, \n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 102us/step\n",
      "testing data 的正確率： 0.9732\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict_classes(x_test)\n",
    "score = model_mix.evaluate(x_test, y_test)\n",
    "print('testing data 的正確率：', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0277 - acc: 0.8077 - val_loss: 0.0162 - val_acc: 0.8954\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0153 - acc: 0.9010 - val_loss: 0.0149 - val_acc: 0.9024\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0134 - acc: 0.9123 - val_loss: 0.0131 - val_acc: 0.9131\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0123 - acc: 0.9200 - val_loss: 0.0118 - val_acc: 0.9229\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0122 - acc: 0.9201 - val_loss: 0.0120 - val_acc: 0.9210\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0118 - acc: 0.9233 - val_loss: 0.0122 - val_acc: 0.9206\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0109 - acc: 0.9290 - val_loss: 0.0107 - val_acc: 0.9289\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0105 - acc: 0.9311 - val_loss: 0.0108 - val_acc: 0.9286\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0108 - acc: 0.9286 - val_loss: 0.0105 - val_acc: 0.9317\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0099 - acc: 0.9353 - val_loss: 0.0100 - val_acc: 0.9353\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0099 - acc: 0.9355 - val_loss: 0.0100 - val_acc: 0.9348\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0095 - acc: 0.9377 - val_loss: 0.0094 - val_acc: 0.9399\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0092 - acc: 0.9392 - val_loss: 0.0091 - val_acc: 0.9400\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0087 - acc: 0.9430 - val_loss: 0.0090 - val_acc: 0.9407\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0085 - acc: 0.9447 - val_loss: 0.0089 - val_acc: 0.9423\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0086 - acc: 0.9437 - val_loss: 0.0082 - val_acc: 0.9458\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0086 - acc: 0.9435 - val_loss: 0.0089 - val_acc: 0.9399\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0082 - acc: 0.9467 - val_loss: 0.0087 - val_acc: 0.9428\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0084 - acc: 0.9454 - val_loss: 0.0091 - val_acc: 0.9391\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0082 - acc: 0.9468 - val_loss: 0.0087 - val_acc: 0.9435\n"
     ]
    }
   ],
   "source": [
    "model_tanh = Sequential()\n",
    "\n",
    "model_tanh.add(Dense(200, input_dim=784))\n",
    "model_tanh.add(Activation('tanh'))\n",
    "model_tanh.add(Dense(100))\n",
    "model_tanh.add(Activation('tanh'))\n",
    "model_tanh.add(Dense(10))\n",
    "model_tanh.add(Activation('softmax'))\n",
    "\n",
    "model_tanh.compile(loss='mse',optimizer=Adam(lr=0.001) ,metrics=['accuracy'])\n",
    "\n",
    "model_tanh_fit=model_tanh.fit(x_train, y_train, batch_size=500, epochs=20,verbose=1, \n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 87us/step\n",
      "testing data 的正確率： 0.9435\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict_classes(x_test)\n",
    "score = model_tanh.evaluate(x_test, y_test)\n",
    "print('testing data 的正確率：', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1624905eb38>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_mix1_fit.history[\"acc\"])\n",
    "plt.plot(model_mix_fit.history[\"acc\"])\n",
    "plt.plot(model_tanh_fit.history[\"acc\"])\n",
    "\n",
    "plt.title(\"model training accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"model_mix1\", \"model_mix\",'model_tanh'], loc = \"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最後訓練了三個設定不太一樣但結果都很不錯的模型，預測準確率在94%~97%的區間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
